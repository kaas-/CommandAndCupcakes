\chapter{On attention and the measurement thereof}\label{ch:attention}
Attention is a subject which has been discussed across various disciplines, which naturally leads to several definitions. Attention can be considered the allocation of cognitive resources to a certain task or stimulus; it can be the acquisition of information through senses such as sight; or it can be the passing of information to a person’s memory. In order to make the discussion of attention more comprehensible, one may distinguish between various different types of attention. As described by Mancas et al. (2016) \cite{Mancas2016}, when addressing visual attention, one may distinguish between \textit{overt} and \textit{covert} attention. Examples of how overt attention manifests are changes in posture, eye and head movements, and changes in pupil size. It deals with things that are fixated upon by the eyes. Covert attention is not as easily observed, but deals with information about a scene gathered with the peripheral vision rather than information which has been fixated on. Another way to describe different types of attention is to divide it into the following five categories:

\begin{enumerate}
\item \textit{Focused} attention: a specific task or stimulus is focused on.
\item \textit{Sustained} attention: one stays attentive for an extended period of time.
\item \textit{Selective} attention: a specific task or stimulus is focused on, while ignoring distracting factors.
\item \textit{Alternating} attention: multiple tasks are switched between.
\item \textit{Divided} attention: multiple tasks are dealt with simultaneously.
\end{enumerate}

When describing how a subject deals with multiple tasks or stimuli, one may distinguish between \textit{serial} and \textit{parallel} attention. Serial attention deals with the given stimuli one after another, whereas parallel attention deals with simultaneous processing of several tasks.

The terms presented here can be used to describe specific types of attention, and may be useful when analysing the results from the final experiment.

\section{Methods of measuring attention}\label{sec:measurement}
As this paper seeks to investigate the effect various factors will have on a player’s attention, it is necessary to consider some methods with which attention can be measured. One possibility is to measure a test subject’s Secondary Task Response Time (STRT). As Lang et al. (2009) \cite{Lang2009} describes it, this method involves a test subject who is given two tasks: a primary task, such as viewing a video, which is presented as the most important of the two; and a secondary task, such as pressing a button when a certain sound is heard. In this case, the time that elapses between the moment the sound is played and the moment the subject presses the button is referred to as the STRT. In theory, this method indicates the amount of attention allocated for the primary task by measuring the amount available for the secondary task --- these should be in inverse proportion to one another. However, the data gathered by Lang et al.\cite{Lang2009} indicates that this is not the case, and the entire methodology may be flawed.
\todo{Margarita: maybe avoid describing the STRT alltogether, since we already mention that this method might be flawed.}

Another method for measuring a subject’s attention is through eye tracking. More specifically, this method is a way to map a subject’s overt attention. This can be done by using a video camera and image processing software to detect the edge of the pupil. For more precise results, one may stabilise the position of the subject’s head, i.e. by using a chin rest. However, stabilising the player’s head is not suitable for the Airconsole platform, since the player needs to alternate between facing the computer screen and the smartphone screen. The quality of the results from such a test is limited by the resolution and frame rate of the camera used, as well as the speed of the image processing algorithm. Results may also be obscured by changes in lighting, dark eye colours which have little contrast to the pupils, and subjects wearing glasses which may cause stray reflections. In order to alleviate some of these issues, hardware specific to eye tracking, such as the \textit{Tobii EyeX eye tracker} \cite{TobiiPro}, can be used instead of a regular video camera. This eye tracking hardware, consisting of cameras and near-infrared illuminators, is placed in front of the subject, just beneath the screen which they are viewing, as is seen in figure \ref{fig:tobii}. Near-infrared light illuminates the subject, casting a pattern of non-visible light on their eyes, of which high-resolution images are taken. An algorithm uses information about the infrared light reflected from the pupil and the cornea to produce a 3D model of the eye, which is then used to calculate the gaze direction relative to the screen. All of this is summarised in figure \ref{fig:tobii}.

\begin{figure}[h!]
	\centering
	\includegraphics[width=\textwidth]{figures/tobii.jpg}
	\caption{Overview of how the Tobii eye tracker works \cite{TobiiPro}.\label{fig:tobii}}
\end{figure}

When analysing data gathered from an eye tracking test, it is important to distinguish between different types of eye movements, as described by Mancas et al.:

\begin{itemize}
\item \textit{Fixations}: the gaze stays on approximately the same area for a period of time. One should note that the gaze is never completely still; even when a subject focuses on a certain location, small saccades can still be detected.
\item \textit{Saccades}: the gaze shifts from one fixation to another. Between these two fixations, no visual information is gathered.
\item \textit{Smooth pursuit}: the gaze fixates on a moving object, following its movements. As with fixation, microsaccades are done to correct position errors.
\end{itemize}

Results from an eye tracking test can be presented in several ways. They can simply display the path travelled by the gaze, referred to as a \textit{scan path}, or they can show \textit{heat maps} of the scan path, typically accumulating scan paths from ten or more test subjects. \todo{Remember to add image examples of these, and also talk about video output}

Although results from such a test may provide an indication of where the subject’s attention is directed, the eye tracking method may not be sufficient in and of itself; as it is mentioned by Snowden et al.\cite{snowden2012basic}: “merely having our eyes pointing in the right direction is not enough to ensure that we will process or appreciate the information”. Therefore, it would be sensible to combine eye tracking with other methods, such as a questionnaire, to acquire a more detailed and reliable feedback from the participants.

\section{Directing Attention}\label{sec:direct_attention}
In order to have a better understanding of how the final design of a game should look like, there is a need to explore different ways of directing attention of a player. It is therefore important to understand how the attentional mechanisms operate in the human mind.


In general, two distinct forms of attention are recognized. The former is described as ‘‘exogenous’’ attention which is driven by stimulus and “captured reflexively by events in a bottom-up manner” \cite{lee2011efficient}. It is also referred to as the pre-attentive stage of attention \cite{zhai2008scalable}. The latter, ‘‘endogenous’’ attention, is dependant on the goals of an individual and “is directed voluntarily in a top-down manner” \cite{lee2011efficient}. It is also known as the attentive stage of attention \cite{zhai2008scalable}. It is worth noting that “hardly any search is purely bottom-up or purely top-down driven” \cite{melloni2012interaction}. In the following subchapters, those two forms of attention are explained in greater detail.

\subsection{Button-up attention}\label{subsec:buttonup attention}
Bottom-up attention means that an object is immediately and involuntarily noticed by an individual because of its salient features \cite{melloni2012interaction}. Those kind of features include intensity, size, depth, color, orientation and movement \cite{zhai2008scalable}. For example, in Figure \ref{fig:visual_search_paradign_i} it is easy to spot the black line no matter the amount of white ones present. Figure \ref{fig:visual_search_paradign_i} also shows typical results from an experiment where the participants were asked to detect an odd item in a picture similar to Figure \ref{fig:visual_search_paradign_i}. As shown in Figure \ref{fig:visual_search_paradign_i} the full line represents the reaction time to notice the target, where the striped line represents the reaction time to notice no target was present. The results were not influenced by the amount of additional non-target items in the picture \cite{snowden2012basic}.

\begin{figure}[h!]
	\centering
	\includegraphics[width=\textwidth]{figures/Visual_search_paradigm_I.jpg}
	\caption{Example graphic for feature map testing (L) with corresponding results \cite{snowden2012basic}}.\label{fig:visual_search_paradign_i}
\end{figure}

The feature integration theory suggests that during the pre-attentive phase there is a mental system of modules, each of which is designed to identify a feature. A module, in turn, has a several feature maps, for instance a colour module can have maps for green, red and purple. All of the features are then combined together through focal attention, where the brain combines the input from the feature maps. When an item stands out due to its feature (for example a green stripe amongst pruple stripes), it is identified easily by its exclusivity in a feature map, as seen in Figure \ref{fig:feature_integration_theory}. The theory explains why finding a circle in a field of lollipops is harder than the inverse, as demonstrated in Figure \ref{fig:circle_lollipop_example}, as the lollipop in the field of circles covers two feature maps and one of the feature maps, the one with lines, only have one object. However with the circle in the field of lollipops, both feature maps, lines and circles, have multiple objects so finding the lone circle is not as fast. This is for example the concept in the “Where’s Wally?” books, where the images contains large amounts of features with multiple objects in each feature map, and ask the reader to find one specific combination of them (glasses, striped blouse and hat, cane, etc)\cite{snowden2012basic}.

\begin{figure}[h!]
	\centering
	\includegraphics[width=\textwidth]{figures/feature_integration_theory.jpg}
	\caption{Feature Integration Theory illustrated \cite{snowden2012basic}}.\label{fig:feature_integration_theory}
\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[width=\textwidth]{figures/circle_lollipop_example.jpg}
	\caption{Circle target vs. lollipop target example \cite{snowden2012basic}}.\label{fig:circle_lollipop_example}
\end{figure}

It is also worth noting that a certain size of an object may attract more attention: in general, larger areas are paid more attention to, than smaller ones, but after a certain saturation point the importance of size diminishes. Besides that, regions with a long and thin edge-like shape attract more attention compared to rounder regions. In addition, motion is considered to have one of the strongest influences on visual attention. “Our peripheral vision is highly tuned to detecting changes in motion, and our attention is involuntarily drawn to peripheral areas undergoing motion distinct from its surrounds” \cite{osberger1998automatic}. 


Auditory stimuli also play an important role in directing attention. “In exogenous spatial attention, it has been proved that a spatially non-predictive cue in one modality can attract covert attention toward the location of the cue in the other modality, which is called the ‘‘cross-modal facilitatory effect.’’” An example of such an effect could be when an unexpected sound source attracts immediate visual attention. Furthermore, moving objects that emit sound are generally paid more attention to than others \cite{lee2011efficient}.

\subsection{Top-down attention}\label{subsec:topdown_attention}
As mentioned before, the top-down attention is highly dependant on the task at hand. In one of the studies, a person was asked to perform several different tasks while looking at a picture. The movements of the eye were recorded. Figure \ref{fig:eye_movement_recording} shows the scan paths that were recorded during the fulfilment of seven tasks: “(1) free examination of the picture, (2) estimate the material circumstances of the family, (3) give the ages of the people, (4) guess what the family had been doing before arrival of the unexpected visitor, (5) remember the clothes worn by the people, (6) remember the position of the people and the objects in the room, and (7) estimate how long the unexpected visitor had been away.” The study clearly indicates that the movements of the eyes are dependant on the goals of an individual \cite{sundstedt2012gazing}. 

\begin{figure}[h!]
	\centering
	\includegraphics[width=\textwidth]{figures/eye_movement_recording.jpg}
	\caption{Recordings of eye tracking in response to different tasks \cite{sundstedt2012gazing}}.\label{fig:eye_movement_recording}
\end{figure}

In another study, when participants were asked to view a kitchen scene freely, the results showed that people tend to focus on the objects of the image, rather than on uniform surfaces like walls. Other studies also showed that when participants were asked to perform a specific assignment, most of the focus was on objects related to the task at hand \cite{sundstedt2012gazing}. 


In addition to that, people usually tend to look at the centre of a screen for most of the time and are more likely to focus on the foreground of a scene \cite{osberger1998automatic}.