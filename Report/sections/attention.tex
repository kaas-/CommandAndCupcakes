%!TEX root = ../master.tex
\chapter{Measuring and Directing Attention}\label{ch:attention}
Attention is a subject which has been discussed across various disciplines, which naturally leads to several definitions. Attention can be considered the allocation of cognitive resources to a certain task or stimulus; it can be the acquisition of information through senses such as sight; or it can be the passing of information to a person’s memory. In order to make the discussion of attention more comprehensible, one may distinguish between various different types of attention. As described by Mancas et al. (2016) \cite{Mancas2016}, when addressing visual attention, one may distinguish between \textit{overt} and \textit{covert} attention. Examples of how overt attention manifests are changes in posture, eye and head movements, and changes in pupil size. It deals with things that are fixated upon by the eyes. Covert attention is not as easily observed, but deals with information about a scene gathered with the peripheral vision rather than information which has been fixated on. Another way to describe different types of attention is to divide it into the following five categories:

\begin{enumerate}
\item \textit{Focused} attention: a specific task or stimulus is focused on.
\item \textit{Sustained} attention: one stays attentive for an extended period of time.
\item \textit{Selective} attention: a specific task or stimulus is focused on, while ignoring distracting factors.
\item \textit{Alternating} attention: multiple tasks are switched between.
\item \textit{Divided} attention: multiple tasks are dealt with simultaneously.
\end{enumerate}

When describing how a subject deals with multiple tasks or stimuli, one may distinguish between \textit{serial} and \textit{parallel} attention. Serial attention deals with the given stimuli one after another, whereas parallel attention deals with simultaneous processing of several tasks.

The terms presented here can be used to describe specific types of attention, and may be useful when analysing the results from the final experiment.

\section{Methods of measuring attention}\label{sec:measurement}
As this paper seeks to investigate the effect various factors will have on a player’s attention, it is necessary to consider some methods with which attention can be measured. One possibility is to measure a test subject’s Secondary Task Response Time (STRT). As Lang et al. (2009) \cite{Lang2009} describes it, this method involves a test subject who is given two tasks: a primary task, such as viewing a video, which is presented as the most important of the two; and a secondary task, such as pressing a button when a certain sound is heard. In this case, the time that elapses between the moment the sound is played and the moment the subject presses the button is referred to as the STRT. In theory, this method indicates the amount of attention allocated for the primary task by measuring the amount available for the secondary task --- these should be in inverse proportion to one another. However, the data gathered by Lang et al.\cite{Lang2009} indicates that this is not the case, and the entire methodology may be flawed.
\todo{Margarita: maybe avoid describing the STRT alltogether, since we already mention that this method might be flawed.}

Another method for measuring a subject’s attention is through eye tracking. More specifically, this method is a way to map a subject’s overt attention. This can be done by using a video camera and image processing software to detect the edge of the pupil. For more precise results, one may stabilise the position of the subject’s head, i.e. by using a chin rest. However, stabilising the player’s head is not suitable for the Airconsole platform, since the player needs to alternate between facing the computer screen and the smartphone screen. The quality of the results from such a test is limited by the resolution and frame rate of the camera used, as well as the speed of the image processing algorithm. Results may also be obscured by changes in lighting, dark eye colours which have little contrast to the pupils, and subjects wearing glasses which may cause stray reflections. In order to alleviate some of these issues, hardware specific to eye tracking, such as the \textit{Tobii EyeX eye tracker} \cite{TobiiPro}, can be used instead of a regular video camera. This eye tracking hardware, consisting of cameras and near-infrared illuminators, is placed in front of the subject, just beneath the screen which they are viewing, as is seen in figure \ref{fig:tobii}. Near-infrared light illuminates the subject, casting a pattern of non-visible light on their eyes, of which high-resolution images are taken. An algorithm uses information about the infrared light reflected from the pupil and the cornea to produce a 3D model of the eye, which is then used to calculate the gaze direction relative to the screen. All of this is summarised in figure \ref{fig:tobii}.

\begin{figure}[h!]
	\centering
	\includegraphics[width=\textwidth]{figures/tobii.jpg}
	\caption{Overview of how the Tobii eye tracker works \cite{TobiiPro}.\label{fig:tobii}}
\end{figure}

When analysing data gathered from an eye tracking test, it is important to distinguish between different types of eye movements, as described by Mancas et al.:

\begin{itemize}
\item \textit{Fixations}: the gaze stays on approximately the same area for a period of time. One should note that the gaze is never completely still; even when a subject focuses on a certain location, small saccades can still be detected.
\item \textit{Saccades}: the gaze shifts from one fixation to another. Between these two fixations, no visual information is gathered.
\item \textit{Smooth pursuit}: the gaze fixates on a moving object, following its movements. As with fixation, microsaccades are done to correct position errors.
\end{itemize}

Results from an eye tracking test can be presented in several ways. They can simply display the path travelled by the gaze, referred to as a \textit{scan path}, or they can show \textit{heat maps} of the scan path, typically accumulating scan paths from ten or more test subjects. \todo{Remember to add image examples of these, and also talk about video output}

Although results from such a test may provide an indication of where the subject’s attention is directed, the eye tracking method may not be sufficient in and of itself; as it is mentioned by Snowden et al.\cite{snowden2012basic}: “merely having our eyes pointing in the right direction is not enough to ensure that we will process or appreciate the information”. Therefore, it would be sensible to combine eye tracking with other methods, such as a questionnaire, to acquire a more detailed and reliable feedback from the participants.

\section{Directing Attention}\label{sec:direct_attention}
In order to have a better understanding of how the final design of a game should look, there is a need to explore different ways of directing a player's attention. It is therefore important to understand how the attentional mechanisms operate in the human mind.

In general, two distinct forms of attention are recognized. The first is described as \textit{exogenous} attention, which is driven by stimulus and, as described by Lee et al. (2011), “captured reflexively by events in a bottom-up manner” \cite{lee2011efficient}. It is also referred to as the pre-attentive stage of attention \cite{zhai2008scalable}. The second, \textit{endogenous} attention, is dependant on the goals of an individual, and as Lee et al. (2011) describes it, “is directed voluntarily in a top-down manner” \cite{lee2011efficient}. It is also known as the attentive stage of attention \cite{zhai2008scalable}. It is worth noting that, as stated by Melloni et al. (2012), “hardly any search is purely bottom-up or purely top-down driven” \cite{melloni2012interaction}. In the following sections, those two forms of attention are explained in greater detail.

\subsection{Bottom-up attention}\label{subsec:bottomup_attention}
\textit{Bottom-up} attention means that an object is immediately and involuntarily noticed by an individual because of its salient features \cite{melloni2012interaction}. Those kinds of features include intensity, size, depth, colour, orientation, and movement \cite{zhai2008scalable}. For example, in Figure \ref{fig:visual_search_paradign_i} it is easy to spot the black line no matter the amount of white ones present. Figure \ref{fig:visual_search_paradign_i} also shows typical results from an experiment in which the participants are asked to detect an odd item in a picture similar to the one seen in the figure. The full line represents the reaction time to notice the target, whereas the dashed line represents the reaction time to notice that no target is present. It is clear that the results are not influenced by the amount of non-target items (the white lines) in the picture \cite{snowden2012basic}.

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.5\textwidth]{figures/Visual_search_paradigm_I.jpg}
	\caption{Example graphic for feature map testing (L) with corresponding results (R) \cite{snowden2012basic}.}\label{fig:visual_search_paradign_i}
\end{figure}

The feature integration theory suggests that during the pre-attentive phase there is a mental system of modules, each of which is designed to identify a feature. A module, in turn, has several feature maps, for instance a colour module can have maps for green, red and purple. All of the features are then combined through focal attention, where the brain combines the input from the feature maps. When an item stands out due to its feature (for example a green stripe amongst purple stripes), it is identified easily by its exclusivity in a feature map, as seen in Figure \ref{fig:feature_integration_theory}. The theory explains why finding a circle in a field of lollipops is harder than the inverse, as demonstrated in Figure \ref{fig:circle_lollipop_example}, as the lollipop in the field of circles covers two feature maps and one of the feature maps, the one with lines, only have one object. However, when it comes to the circle in the field of lollipops, both feature maps, lines and circles, have multiple objects, so the process of finding the lone circle is not as fast. This is the same concept as the “Where’s Wally?” books, where the images contain large amounts of features with multiple objects in each feature map, and ask the reader to find one specific combination of them (glasses, striped blouse and hat, cane, etc.).

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.5\textwidth]{figures/feature_integration_theory.jpg}
	\caption{Feature Integration Theory illustrated \cite{snowden2012basic}.}\label{fig:feature_integration_theory}
\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.5\textwidth]{figures/circle_lollipop_example.jpg}
	\caption{Circle target vs. lollipop target example \cite{snowden2012basic}.}\label{fig:circle_lollipop_example}
\end{figure}

It is also worth noting that a certain size of an object may attract more attention: in general, larger areas receive more attention than smaller ones, but after a certain saturation point, the importance of size diminishes. Besides that, regions with long and thin edge-like shapes attract more attention compared to rounder regions. In addition, motion is considered to have one of the strongest influences on visual attention. As Osberger and Maeder (1998) state: “Our peripheral vision is highly tuned to detecting changes in motion, and our attention is involuntarily drawn to peripheral areas undergoing motion distinct from its surrounds” \cite{osberger1998automatic}. 

Auditory stimuli also play an important role in directing attention. As stated by Lee et al.: “In exogenous spatial attention, it has been proved that a spatially non-predictive cue in one modality can attract covert attention toward the location of the cue in the other modality, which is called the ‘‘cross-modal facilitatory effect.’’” \cite{Lee2011704}. An example of such an effect could be when an unexpected sound source attracts immediate visual attention. Furthermore, moving objects that emit sound are generally paid more attention to than others, according to Lee et al. \cite{lee2011efficient}.

\subsection{Top-down attention}\label{subsec:topdown_attention}
As mentioned before, \textit{top-down} attention is highly dependant on the task at hand. In a study conducted by Yarbus (1967), a person was asked to perform several different tasks while looking at a picture. The movements of the eye were recorded. Figure \ref{fig:eye_movement_recording} shows the scan paths that were recorded during the fulfilment of seven tasks: (1) free examination of the picture, (2) estimate the material circumstances of the family, (3) give the ages of the people, (4) guess what the family had been doing before arrival of the unexpected visitor, (5) remember the clothes worn by the people, (6) remember the position of the people and the objects in the room, and (7) estimate how long the unexpected visitor had been away. The study clearly indicates that the movements of the eyes are dependant on the goals of an individual. \cite{Yarbus1967}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.5\textwidth]{figures/eye_movement_recording.jpg}
	\caption{Recordings of eye tracking in response to different tasks \cite{sundstedt2012gazing}}.\label{fig:eye_movement_recording}
\end{figure}

In Yarbus' study, when participants were asked to view the scene freely, the results showed that people tend to focus on the objects of the image, rather than on uniform surfaces like walls or floors. Furthermore, all participants showed similar scan paths when viewing the image freely. Another study, conducted by Land et al. (1999), also showed that when participants were asked to perform a specific assignment, most of the focus was on objects related to the task at hand \cite{Land1999}.
In addition to that, people usually tend to look at the centre of a screen for most of the time and are more likely to focus on the foreground of a scene, as stated by Osberger and Maeder (1998) \cite{osberger1998automatic}.

To summarise, the main factors to manipulate when directing attention are sound, movement and differences in colours. Tactile feedback is not referenced in these papers since they do not deal with mediums which make tactile feedback relevant. For this project, tactile feedback is also a factor which can be manipulated when directing attention. 

This project will not direct attention in a single person setup as the research papers referenced have. There will be multiple people during these tests, and the goal is to direct attention individually without distracting the other participants. Sound, depending on the volume, might be a distraction to the other participants. Dramatic movement of the playable characters might also be a distraction. This means that other ways of directing attention have to be modulated to fit a multi-person setup. For this purpose, the tactile feedback provided by the smartphones can be a useful replacement for the sound, i.e. the phone vibrates when the participant's character collects a map piece. If players engage in combat their smartphones could play a loud sound to direct their attention there. Alternatively, a player's smartphone could vibrate when it is their turn, and when they engage in combat. Another possibility is to provide visual on where the player should look, either with a focus on colour (i.e. a given player's colour may take up a certain amount of the screen when it is their turn) or movement (i.e. a moving icon may pop up on the screen when players are engaged in combat). The position of the visual feedback may have an effect on where a player directs their attention. All of these are factors which can be isolated and tested in the experiment of this project.

To conclude on the assumptions made on multi-person setups based on the research found on single person setups, the same principles can be applied. However, one must take into consideration how they can distract the other participants. The solution in this project might be to take advantage of all participants having their own smartphone in addition to the main screen, and therefore have a direct device to direct their attention without distracting the other participants.